{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請改變 reduce_lr 的 patience 和 factor 並比較不同設定下，對訓練/驗證集的影響\n",
    "2. 請將 optimizer 換成 Adam、RMSprop 搭配 reduce_lr 並比較訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[256, 256, 256]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 25 # IF you feel too run to finish, try to make it smaller\n",
    "BATCH_SIZE = 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "optimizer_set = [keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=0.95),\n",
    "                 keras.optimizers.Adam(lr=LEARNING_RATE),\n",
    "                 keras.optimizers.RMSprop(lr=LEARNING_RATE)]\n",
    "\n",
    "\"\"\"Code Here\n",
    "建立實驗的比較組合\n",
    "\"\"\"\n",
    "reduce_lr_factor = [0.2, 0.4, 0.6]\n",
    "redice_lr_patient = [3, 5,10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, reduce_factor: 0.20, reduce_patient: 3, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_178 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_180 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 19s 370us/step - loss: 2.2618 - acc: 0.2600 - val_loss: 2.2852 - val_acc: 0.2898\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.7769 - acc: 0.3817 - val_loss: 1.8538 - val_acc: 0.3622\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.6428 - acc: 0.4248 - val_loss: 1.7182 - val_acc: 0.4064\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.5666 - acc: 0.4505 - val_loss: 1.6536 - val_acc: 0.4266\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.5126 - acc: 0.4708 - val_loss: 1.6247 - val_acc: 0.4316\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4683 - acc: 0.4877 - val_loss: 1.5693 - val_acc: 0.4544\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.4294 - acc: 0.5009 - val_loss: 1.5654 - val_acc: 0.4570\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.3963 - acc: 0.5130 - val_loss: 1.5284 - val_acc: 0.4663\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.3662 - acc: 0.5236 - val_loss: 1.5159 - val_acc: 0.4767\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3389 - acc: 0.5357 - val_loss: 1.5009 - val_acc: 0.4790\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.3129 - acc: 0.5434 - val_loss: 1.4986 - val_acc: 0.4800\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.2895 - acc: 0.5537 - val_loss: 1.4868 - val_acc: 0.4834\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.2673 - acc: 0.5599 - val_loss: 1.4698 - val_acc: 0.4856\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2461 - acc: 0.5678 - val_loss: 1.4603 - val_acc: 0.4885\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.2249 - acc: 0.5766 - val_loss: 1.4669 - val_acc: 0.4868\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.2070 - acc: 0.5814 - val_loss: 1.4504 - val_acc: 0.4949\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1850 - acc: 0.5904 - val_loss: 1.4438 - val_acc: 0.4967\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.1678 - acc: 0.5956 - val_loss: 1.4481 - val_acc: 0.4940\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1497 - acc: 0.6030 - val_loss: 1.4481 - val_acc: 0.4951\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.1317 - acc: 0.6092 - val_loss: 1.4341 - val_acc: 0.5013\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1136 - acc: 0.6161 - val_loss: 1.4416 - val_acc: 0.4996\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.0961 - acc: 0.6231 - val_loss: 1.4427 - val_acc: 0.4957\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.0803 - acc: 0.6294 - val_loss: 1.4507 - val_acc: 0.4944\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.0610 - acc: 0.6376 - val_loss: 1.4300 - val_acc: 0.5003\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.0423 - acc: 0.6456 - val_loss: 1.4233 - val_acc: 0.5040\n",
      "Numbers of exp: 1, reduce_factor: 0.20, reduce_patient: 5, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_181 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_182 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_183 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 2.5543 - acc: 0.1923 - val_loss: 2.3735 - val_acc: 0.2465\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.1115 - acc: 0.2934 - val_loss: 2.1271 - val_acc: 0.2930\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.9478 - acc: 0.3349 - val_loss: 1.9787 - val_acc: 0.3270\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.8571 - acc: 0.3579 - val_loss: 1.8995 - val_acc: 0.3498\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.7929 - acc: 0.3789 - val_loss: 1.8427 - val_acc: 0.3660\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.7450 - acc: 0.3931 - val_loss: 1.8023 - val_acc: 0.3752\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.7073 - acc: 0.4043 - val_loss: 1.7643 - val_acc: 0.3882\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.6747 - acc: 0.4166 - val_loss: 1.7475 - val_acc: 0.3924\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.6463 - acc: 0.4238 - val_loss: 1.7239 - val_acc: 0.4031\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.6212 - acc: 0.4329 - val_loss: 1.7013 - val_acc: 0.4072\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5992 - acc: 0.4408 - val_loss: 1.6889 - val_acc: 0.4118\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.5794 - acc: 0.4465 - val_loss: 1.6734 - val_acc: 0.4165\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5608 - acc: 0.4534 - val_loss: 1.6609 - val_acc: 0.4226\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.5438 - acc: 0.4588 - val_loss: 1.6487 - val_acc: 0.4237\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5286 - acc: 0.4642 - val_loss: 1.6449 - val_acc: 0.4263\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.5139 - acc: 0.4707 - val_loss: 1.6297 - val_acc: 0.4281\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.4997 - acc: 0.4732 - val_loss: 1.6249 - val_acc: 0.4334: 0s - loss: 1.4999 - acc:\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.4877 - acc: 0.4802 - val_loss: 1.6158 - val_acc: 0.4327\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.4746 - acc: 0.4861 - val_loss: 1.6106 - val_acc: 0.4357\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.4638 - acc: 0.4870 - val_loss: 1.6033 - val_acc: 0.4374\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.4522 - acc: 0.4925 - val_loss: 1.5968 - val_acc: 0.4396\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.4410 - acc: 0.4966 - val_loss: 1.5933 - val_acc: 0.4412\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.4318 - acc: 0.4999 - val_loss: 1.5844 - val_acc: 0.4444\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.4212 - acc: 0.5042 - val_loss: 1.5823 - val_acc: 0.4446\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.4116 - acc: 0.5072 - val_loss: 1.5764 - val_acc: 0.4459\n",
      "Numbers of exp: 2, reduce_factor: 0.20, reduce_patient: 10, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_184 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_185 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_186 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 2.6139 - acc: 0.1773 - val_loss: 2.4361 - val_acc: 0.2372\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 2.1046 - acc: 0.2922 - val_loss: 2.1500 - val_acc: 0.2948\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.9452 - acc: 0.3370 - val_loss: 1.9896 - val_acc: 0.3262\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.8590 - acc: 0.3604 - val_loss: 1.9138 - val_acc: 0.3468\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.7966 - acc: 0.3760 - val_loss: 1.8458 - val_acc: 0.3611\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.7502 - acc: 0.3933 - val_loss: 1.8140 - val_acc: 0.3771\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.7126 - acc: 0.4037 - val_loss: 1.7785 - val_acc: 0.3852\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.6803 - acc: 0.4146 - val_loss: 1.7555 - val_acc: 0.3874\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6518 - acc: 0.4230 - val_loss: 1.7328 - val_acc: 0.3986\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6282 - acc: 0.4295 - val_loss: 1.7115 - val_acc: 0.4027\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.6058 - acc: 0.4391 - val_loss: 1.7015 - val_acc: 0.4066\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.5871 - acc: 0.4449 - val_loss: 1.6869 - val_acc: 0.4159\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.5691 - acc: 0.4505 - val_loss: 1.6740 - val_acc: 0.4176\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5529 - acc: 0.4564 - val_loss: 1.6616 - val_acc: 0.4215\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.5366 - acc: 0.4625 - val_loss: 1.6550 - val_acc: 0.4221\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.5227 - acc: 0.4666 - val_loss: 1.6431 - val_acc: 0.4285\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5099 - acc: 0.4703 - val_loss: 1.6342 - val_acc: 0.4314\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.4960 - acc: 0.4749 - val_loss: 1.6284 - val_acc: 0.4313\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.4846 - acc: 0.4784 - val_loss: 1.6206 - val_acc: 0.4343\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.4718 - acc: 0.4861 - val_loss: 1.6142 - val_acc: 0.4384\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.4607 - acc: 0.4887 - val_loss: 1.6082 - val_acc: 0.4379\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.4496 - acc: 0.4915 - val_loss: 1.6009 - val_acc: 0.4434\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.4383 - acc: 0.4959 - val_loss: 1.5933 - val_acc: 0.4473\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.4295 - acc: 0.4992 - val_loss: 1.5881 - val_acc: 0.4471\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.4194 - acc: 0.5043 - val_loss: 1.5839 - val_acc: 0.4479\n",
      "Numbers of exp: 3, reduce_factor: 0.40, reduce_patient: 3, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_188 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_189 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 2.5528 - acc: 0.1821 - val_loss: 2.4844 - val_acc: 0.2404\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 2.1040 - acc: 0.2862 - val_loss: 2.1132 - val_acc: 0.2940\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.9406 - acc: 0.3314 - val_loss: 1.9744 - val_acc: 0.3217\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.8537 - acc: 0.3568 - val_loss: 1.8835 - val_acc: 0.3462\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.7951 - acc: 0.3748 - val_loss: 1.8243 - val_acc: 0.3626\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.7506 - acc: 0.3880 - val_loss: 1.7979 - val_acc: 0.3724\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.7128 - acc: 0.4013 - val_loss: 1.7692 - val_acc: 0.3797\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.6824 - acc: 0.4119 - val_loss: 1.7438 - val_acc: 0.3889\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.6548 - acc: 0.4206 - val_loss: 1.7256 - val_acc: 0.3955\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.6307 - acc: 0.4285 - val_loss: 1.7058 - val_acc: 0.3994\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6096 - acc: 0.4357 - val_loss: 1.6913 - val_acc: 0.4057\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5903 - acc: 0.4421 - val_loss: 1.6768 - val_acc: 0.4107\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5712 - acc: 0.4489 - val_loss: 1.6615 - val_acc: 0.4170\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5548 - acc: 0.4546 - val_loss: 1.6528 - val_acc: 0.4151\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5395 - acc: 0.4614 - val_loss: 1.6454 - val_acc: 0.4200\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.5250 - acc: 0.4665 - val_loss: 1.6294 - val_acc: 0.4281\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5101 - acc: 0.4701 - val_loss: 1.6256 - val_acc: 0.4272\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.4978 - acc: 0.4771 - val_loss: 1.6137 - val_acc: 0.4354\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4854 - acc: 0.4803 - val_loss: 1.6093 - val_acc: 0.4332\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4728 - acc: 0.4831 - val_loss: 1.5987 - val_acc: 0.4412\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4619 - acc: 0.4860 - val_loss: 1.5945 - val_acc: 0.4414\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4522 - acc: 0.4916 - val_loss: 1.5903 - val_acc: 0.4405\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4407 - acc: 0.4968 - val_loss: 1.5826 - val_acc: 0.4451\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4300 - acc: 0.4999 - val_loss: 1.5771 - val_acc: 0.4484\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4203 - acc: 0.5023 - val_loss: 1.5719 - val_acc: 0.4508\n",
      "Numbers of exp: 4, reduce_factor: 0.40, reduce_patient: 5, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_64 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_191 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_192 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 2.5725 - acc: 0.1825 - val_loss: 2.4761 - val_acc: 0.2443\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 2.1082 - acc: 0.2880 - val_loss: 2.1021 - val_acc: 0.2963\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.9475 - acc: 0.3299 - val_loss: 1.9802 - val_acc: 0.3253\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.8598 - acc: 0.3555 - val_loss: 1.8984 - val_acc: 0.3483\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.7973 - acc: 0.3752 - val_loss: 1.8546 - val_acc: 0.3567\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.7508 - acc: 0.3910 - val_loss: 1.8093 - val_acc: 0.3748\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.7126 - acc: 0.4022 - val_loss: 1.7804 - val_acc: 0.3813\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6822 - acc: 0.4149 - val_loss: 1.7539 - val_acc: 0.3916\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.6542 - acc: 0.4217 - val_loss: 1.7314 - val_acc: 0.3995\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.6308 - acc: 0.4320 - val_loss: 1.7097 - val_acc: 0.4049\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6089 - acc: 0.4394 - val_loss: 1.6900 - val_acc: 0.4085\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5899 - acc: 0.4445 - val_loss: 1.6786 - val_acc: 0.4168\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5717 - acc: 0.4524 - val_loss: 1.6664 - val_acc: 0.4150\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5547 - acc: 0.4580 - val_loss: 1.6551 - val_acc: 0.4201\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5407 - acc: 0.4633 - val_loss: 1.6493 - val_acc: 0.4239\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5258 - acc: 0.4685 - val_loss: 1.6359 - val_acc: 0.4272\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5124 - acc: 0.4733 - val_loss: 1.6269 - val_acc: 0.4346\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4992 - acc: 0.4784 - val_loss: 1.6197 - val_acc: 0.4363\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.4871 - acc: 0.4818 - val_loss: 1.6135 - val_acc: 0.4354\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4754 - acc: 0.4857 - val_loss: 1.6059 - val_acc: 0.4378\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4650 - acc: 0.4909 - val_loss: 1.6004 - val_acc: 0.4389\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4534 - acc: 0.4948 - val_loss: 1.5923 - val_acc: 0.4411\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.4422 - acc: 0.4977 - val_loss: 1.5859 - val_acc: 0.4422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4334 - acc: 0.5011 - val_loss: 1.5827 - val_acc: 0.4472\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4239 - acc: 0.5055 - val_loss: 1.5771 - val_acc: 0.4490\n",
      "Numbers of exp: 5, reduce_factor: 0.40, reduce_patient: 10, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_193 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_194 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 2.5687 - acc: 0.1872 - val_loss: 2.3520 - val_acc: 0.2441\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 2.0953 - acc: 0.2955 - val_loss: 2.0948 - val_acc: 0.3073\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.9276 - acc: 0.3385 - val_loss: 1.9567 - val_acc: 0.3341\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.8397 - acc: 0.3628 - val_loss: 1.8731 - val_acc: 0.3581\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.7776 - acc: 0.3826 - val_loss: 1.8281 - val_acc: 0.3710\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.7331 - acc: 0.3973 - val_loss: 1.7848 - val_acc: 0.3853\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.6961 - acc: 0.4103 - val_loss: 1.7569 - val_acc: 0.3940\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.6657 - acc: 0.4172 - val_loss: 1.7325 - val_acc: 0.4010\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.6392 - acc: 0.4270 - val_loss: 1.7079 - val_acc: 0.4093\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.6164 - acc: 0.4345 - val_loss: 1.6913 - val_acc: 0.4144\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.5952 - acc: 0.4426 - val_loss: 1.6770 - val_acc: 0.4224\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5757 - acc: 0.4486 - val_loss: 1.6634 - val_acc: 0.4255\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5591 - acc: 0.4556 - val_loss: 1.6505 - val_acc: 0.4256\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5431 - acc: 0.4612 - val_loss: 1.6448 - val_acc: 0.4273\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5284 - acc: 0.4662 - val_loss: 1.6339 - val_acc: 0.4314\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5148 - acc: 0.4707 - val_loss: 1.6238 - val_acc: 0.4338\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5006 - acc: 0.4770 - val_loss: 1.6151 - val_acc: 0.4359\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4876 - acc: 0.4808 - val_loss: 1.6082 - val_acc: 0.4389\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4765 - acc: 0.4860 - val_loss: 1.6004 - val_acc: 0.4390\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4652 - acc: 0.4892 - val_loss: 1.5924 - val_acc: 0.4428\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4542 - acc: 0.4919 - val_loss: 1.5893 - val_acc: 0.4431\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4436 - acc: 0.4965 - val_loss: 1.5853 - val_acc: 0.4444\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4339 - acc: 0.5005 - val_loss: 1.5775 - val_acc: 0.4478\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4241 - acc: 0.5039 - val_loss: 1.5719 - val_acc: 0.4444\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4159 - acc: 0.5063 - val_loss: 1.5690 - val_acc: 0.4503\n",
      "Numbers of exp: 6, reduce_factor: 0.60, reduce_patient: 3, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_196 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_197 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_198 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 2.5315 - acc: 0.1960 - val_loss: 2.3419 - val_acc: 0.2446\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.0815 - acc: 0.2984 - val_loss: 2.1033 - val_acc: 0.3014\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.9244 - acc: 0.3407 - val_loss: 1.9634 - val_acc: 0.3405\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.8420 - acc: 0.3642 - val_loss: 1.8771 - val_acc: 0.3586\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.7824 - acc: 0.3810 - val_loss: 1.8319 - val_acc: 0.3654\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.7368 - acc: 0.3953 - val_loss: 1.7870 - val_acc: 0.3813\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.7005 - acc: 0.4081 - val_loss: 1.7591 - val_acc: 0.3855\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6693 - acc: 0.4186 - val_loss: 1.7342 - val_acc: 0.3963\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6433 - acc: 0.4271 - val_loss: 1.7117 - val_acc: 0.4016\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6204 - acc: 0.4340 - val_loss: 1.6980 - val_acc: 0.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 1.6003 - acc: 0.4408 - val_loss: 1.6832 - val_acc: 0.4093\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5815 - acc: 0.4484 - val_loss: 1.6683 - val_acc: 0.4151\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.5635 - acc: 0.4541 - val_loss: 1.6559 - val_acc: 0.4186\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.5467 - acc: 0.4610 - val_loss: 1.6457 - val_acc: 0.4223\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5328 - acc: 0.4654 - val_loss: 1.6308 - val_acc: 0.4254\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5180 - acc: 0.4710 - val_loss: 1.6244 - val_acc: 0.4278\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5045 - acc: 0.4753 - val_loss: 1.6188 - val_acc: 0.4319\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4924 - acc: 0.4793 - val_loss: 1.6093 - val_acc: 0.4339\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.4806 - acc: 0.4848 - val_loss: 1.6025 - val_acc: 0.4343\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4693 - acc: 0.4881 - val_loss: 1.5975 - val_acc: 0.4376\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4577 - acc: 0.4916 - val_loss: 1.5896 - val_acc: 0.4428\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.4472 - acc: 0.4961 - val_loss: 1.5838 - val_acc: 0.4418\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.4372 - acc: 0.4991 - val_loss: 1.5792 - val_acc: 0.4467\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.4286 - acc: 0.5008 - val_loss: 1.5743 - val_acc: 0.4484\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.4188 - acc: 0.5068 - val_loss: 1.5683 - val_acc: 0.4488\n",
      "Numbers of exp: 7, reduce_factor: 0.60, reduce_patient: 5, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_199 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_200 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_201 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 16s 321us/step - loss: 2.5707 - acc: 0.1870 - val_loss: 2.4816 - val_acc: 0.2345\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.0918 - acc: 0.2938 - val_loss: 2.0861 - val_acc: 0.3069\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.9361 - acc: 0.3385 - val_loss: 1.9631 - val_acc: 0.3397\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.8478 - acc: 0.3630 - val_loss: 1.8967 - val_acc: 0.3526\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.7875 - acc: 0.3805 - val_loss: 1.8466 - val_acc: 0.3664\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.7409 - acc: 0.3955 - val_loss: 1.8037 - val_acc: 0.3804\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.7041 - acc: 0.4059 - val_loss: 1.7688 - val_acc: 0.3897\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6728 - acc: 0.4155 - val_loss: 1.7477 - val_acc: 0.3931\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6462 - acc: 0.4249 - val_loss: 1.7262 - val_acc: 0.3985\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.6221 - acc: 0.4321 - val_loss: 1.7018 - val_acc: 0.4088\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.6018 - acc: 0.4404 - val_loss: 1.6886 - val_acc: 0.4103\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5805 - acc: 0.4460 - val_loss: 1.6758 - val_acc: 0.4124\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.5647 - acc: 0.4520 - val_loss: 1.6600 - val_acc: 0.4199\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.5464 - acc: 0.4571 - val_loss: 1.6528 - val_acc: 0.4249\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5320 - acc: 0.4642 - val_loss: 1.6451 - val_acc: 0.4244\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5169 - acc: 0.4691 - val_loss: 1.6341 - val_acc: 0.4277\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.5028 - acc: 0.4739 - val_loss: 1.6249 - val_acc: 0.4314\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.4904 - acc: 0.4780 - val_loss: 1.6175 - val_acc: 0.4336\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4779 - acc: 0.4834 - val_loss: 1.6115 - val_acc: 0.4388\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.4649 - acc: 0.4889 - val_loss: 1.6057 - val_acc: 0.4377\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.4548 - acc: 0.4915 - val_loss: 1.5965 - val_acc: 0.4391\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 1.4436 - acc: 0.4952 - val_loss: 1.5920 - val_acc: 0.4408\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.4325 - acc: 0.5000 - val_loss: 1.5839 - val_acc: 0.4439\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.4237 - acc: 0.5024 - val_loss: 1.5827 - val_acc: 0.4443\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.4125 - acc: 0.5071 - val_loss: 1.5749 - val_acc: 0.4465\n",
      "Numbers of exp: 8, reduce_factor: 0.60, reduce_patient: 10, <keras.optimizers.SGD object at 0xb4013c1d0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_202 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_204 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 2.4676 - acc: 0.2012 - val_loss: 2.4475 - val_acc: 0.2500\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 2.0563 - acc: 0.3008 - val_loss: 2.1028 - val_acc: 0.3076\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.9096 - acc: 0.3392 - val_loss: 1.9542 - val_acc: 0.3403\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.8276 - acc: 0.3637 - val_loss: 1.8740 - val_acc: 0.3587\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.7698 - acc: 0.3819 - val_loss: 1.8224 - val_acc: 0.3730\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.7272 - acc: 0.3950 - val_loss: 1.7824 - val_acc: 0.3812\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.6905 - acc: 0.4069 - val_loss: 1.7556 - val_acc: 0.3917\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.6613 - acc: 0.4166 - val_loss: 1.7295 - val_acc: 0.3981\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6354 - acc: 0.4267 - val_loss: 1.7129 - val_acc: 0.4019\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.6121 - acc: 0.4349 - val_loss: 1.6977 - val_acc: 0.4111\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.5904 - acc: 0.4408 - val_loss: 1.6786 - val_acc: 0.4141\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5709 - acc: 0.4497 - val_loss: 1.6672 - val_acc: 0.4172\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5543 - acc: 0.4556 - val_loss: 1.6564 - val_acc: 0.4199\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.5378 - acc: 0.4608 - val_loss: 1.6442 - val_acc: 0.4240\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.5219 - acc: 0.4662 - val_loss: 1.6335 - val_acc: 0.4290\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.5079 - acc: 0.4713 - val_loss: 1.6266 - val_acc: 0.4337\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4949 - acc: 0.4765 - val_loss: 1.6169 - val_acc: 0.4340\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4823 - acc: 0.4798 - val_loss: 1.6091 - val_acc: 0.4352\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4705 - acc: 0.4841 - val_loss: 1.6036 - val_acc: 0.4395\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4585 - acc: 0.4881 - val_loss: 1.5926 - val_acc: 0.4422\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.4473 - acc: 0.4924 - val_loss: 1.5899 - val_acc: 0.4459\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4362 - acc: 0.4959 - val_loss: 1.5838 - val_acc: 0.4461\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.4269 - acc: 0.5009 - val_loss: 1.5794 - val_acc: 0.4472\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.4174 - acc: 0.5029 - val_loss: 1.5772 - val_acc: 0.4452\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.4070 - acc: 0.5079 - val_loss: 1.5702 - val_acc: 0.4497\n",
      "Numbers of exp: 9, reduce_factor: 0.20, reduce_patient: 3, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 1.7822 - acc: 0.3801 - val_loss: 2.0778 - val_acc: 0.3422\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.4842 - acc: 0.4799 - val_loss: 2.0237 - val_acc: 0.3272\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.3789 - acc: 0.5150 - val_loss: 1.9696 - val_acc: 0.3651\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 1.2992 - acc: 0.5413 - val_loss: 2.2639 - val_acc: 0.3085\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2250 - acc: 0.5689 - val_loss: 1.9651 - val_acc: 0.3568\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.1673 - acc: 0.5874 - val_loss: 1.7348 - val_acc: 0.4092\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.1155 - acc: 0.6071 - val_loss: 1.7049 - val_acc: 0.4140\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.0620 - acc: 0.6272 - val_loss: 1.6816 - val_acc: 0.4117\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.0225 - acc: 0.6408 - val_loss: 1.7227 - val_acc: 0.4294\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 0.9678 - acc: 0.6618 - val_loss: 1.8137 - val_acc: 0.4077\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 0.9281 - acc: 0.6757 - val_loss: 1.6441 - val_acc: 0.4476\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 0.8845 - acc: 0.6908 - val_loss: 1.7693 - val_acc: 0.4433\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 0.8287 - acc: 0.7125 - val_loss: 1.6497 - val_acc: 0.4566\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.7983 - acc: 0.7221 - val_loss: 1.8567 - val_acc: 0.4166\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.6605 - acc: 0.7834 - val_loss: 1.3793 - val_acc: 0.5309\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.6048 - acc: 0.8085 - val_loss: 1.3758 - val_acc: 0.5374\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.5841 - acc: 0.8161 - val_loss: 1.3843 - val_acc: 0.5387\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.5635 - acc: 0.8256 - val_loss: 1.4328 - val_acc: 0.5257\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.5463 - acc: 0.8328 - val_loss: 1.4287 - val_acc: 0.5307\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.5090 - acc: 0.8502 - val_loss: 1.4011 - val_acc: 0.5419\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.5002 - acc: 0.8538 - val_loss: 1.4054 - val_acc: 0.5433\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4954 - acc: 0.8557 - val_loss: 1.4146 - val_acc: 0.5429\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4876 - acc: 0.8600 - val_loss: 1.4107 - val_acc: 0.5424\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.4853 - acc: 0.8609 - val_loss: 1.4136 - val_acc: 0.5431\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.4848 - acc: 0.8616 - val_loss: 1.4162 - val_acc: 0.5415\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Numbers of exp: 10, reduce_factor: 0.20, reduce_patient: 5, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 2.6755 - acc: 0.1540 - val_loss: 2.5375 - val_acc: 0.2060\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 2.3815 - acc: 0.2200 - val_loss: 2.3789 - val_acc: 0.2326\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 2.2670 - acc: 0.2487 - val_loss: 2.2880 - val_acc: 0.2500\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.1992 - acc: 0.2637 - val_loss: 2.2262 - val_acc: 0.2621\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.1480 - acc: 0.2762 - val_loss: 2.1753 - val_acc: 0.2726\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 2.1099 - acc: 0.2859 - val_loss: 2.1380 - val_acc: 0.2842\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 2.0787 - acc: 0.2944 - val_loss: 2.1077 - val_acc: 0.2923\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 2.0524 - acc: 0.3023 - val_loss: 2.0822 - val_acc: 0.2992\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 2.0291 - acc: 0.3076 - val_loss: 2.0610 - val_acc: 0.3043\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 2.0081 - acc: 0.3126 - val_loss: 2.0422 - val_acc: 0.3100\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.9908 - acc: 0.3171 - val_loss: 2.0263 - val_acc: 0.3166\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.9741 - acc: 0.3224 - val_loss: 2.0116 - val_acc: 0.3181\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.9583 - acc: 0.3257 - val_loss: 1.9968 - val_acc: 0.3207\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.9450 - acc: 0.3303 - val_loss: 1.9837 - val_acc: 0.3230\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.9320 - acc: 0.3339 - val_loss: 1.9712 - val_acc: 0.3267\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.9191 - acc: 0.3372 - val_loss: 1.9598 - val_acc: 0.3306\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 1.9076 - acc: 0.3415 - val_loss: 1.9495 - val_acc: 0.3336\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.8963 - acc: 0.3444 - val_loss: 1.9400 - val_acc: 0.3369\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.8861 - acc: 0.3478 - val_loss: 1.9312 - val_acc: 0.3398\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.8765 - acc: 0.3516 - val_loss: 1.9228 - val_acc: 0.3419\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8671 - acc: 0.3537 - val_loss: 1.9152 - val_acc: 0.3462\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8581 - acc: 0.3568 - val_loss: 1.9078 - val_acc: 0.3465\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.8492 - acc: 0.3593 - val_loss: 1.9005 - val_acc: 0.3487\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.8416 - acc: 0.3616 - val_loss: 1.8945 - val_acc: 0.3507\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.8344 - acc: 0.3644 - val_loss: 1.8875 - val_acc: 0.3533\n",
      "Numbers of exp: 11, reduce_factor: 0.20, reduce_patient: 10, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 2.6527 - acc: 0.1707 - val_loss: 2.4896 - val_acc: 0.2109\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.3686 - acc: 0.2287 - val_loss: 2.3231 - val_acc: 0.2408\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.2544 - acc: 0.2537 - val_loss: 2.2415 - val_acc: 0.2577\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 2.1810 - acc: 0.2702 - val_loss: 2.1849 - val_acc: 0.2717\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 2.1282 - acc: 0.2837 - val_loss: 2.1395 - val_acc: 0.2800\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.0873 - acc: 0.2950 - val_loss: 2.1037 - val_acc: 0.2903\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 102us/step - loss: 2.0541 - acc: 0.3024 - val_loss: 2.0725 - val_acc: 0.2993\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 2.0278 - acc: 0.3095 - val_loss: 2.0477 - val_acc: 0.3031\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.0037 - acc: 0.3163 - val_loss: 2.0266 - val_acc: 0.3087\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.9828 - acc: 0.3230 - val_loss: 2.0088 - val_acc: 0.3143\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.9641 - acc: 0.3273 - val_loss: 1.9918 - val_acc: 0.3212\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.9463 - acc: 0.3318 - val_loss: 1.9770 - val_acc: 0.3237\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.9315 - acc: 0.3360 - val_loss: 1.9646 - val_acc: 0.3261\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.9175 - acc: 0.3410 - val_loss: 1.9538 - val_acc: 0.3290\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.9052 - acc: 0.3454 - val_loss: 1.9422 - val_acc: 0.3315\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.8926 - acc: 0.3473 - val_loss: 1.9312 - val_acc: 0.3351\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.8816 - acc: 0.3504 - val_loss: 1.9221 - val_acc: 0.3384\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.8711 - acc: 0.3542 - val_loss: 1.9136 - val_acc: 0.3404\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 1.8617 - acc: 0.3571 - val_loss: 1.9054 - val_acc: 0.3433\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.8520 - acc: 0.3599 - val_loss: 1.8980 - val_acc: 0.3442\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.8438 - acc: 0.3623 - val_loss: 1.8904 - val_acc: 0.3454\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8355 - acc: 0.3642 - val_loss: 1.8833 - val_acc: 0.3477\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.8263 - acc: 0.3679 - val_loss: 1.8768 - val_acc: 0.3504\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.8189 - acc: 0.3690 - val_loss: 1.8706 - val_acc: 0.3511\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.8115 - acc: 0.3729 - val_loss: 1.8643 - val_acc: 0.3514\n",
      "Numbers of exp: 12, reduce_factor: 0.40, reduce_patient: 3, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 2.7395 - acc: 0.1483 - val_loss: 2.5356 - val_acc: 0.1995\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 2.3763 - acc: 0.2234 - val_loss: 2.3761 - val_acc: 0.2321\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.2505 - acc: 0.2544 - val_loss: 2.2816 - val_acc: 0.2552\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 2.1766 - acc: 0.2739 - val_loss: 2.2133 - val_acc: 0.2722\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 2.1244 - acc: 0.2876 - val_loss: 2.1607 - val_acc: 0.2839\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 2.0855 - acc: 0.2960 - val_loss: 2.1217 - val_acc: 0.2945\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 2.0518 - acc: 0.3044 - val_loss: 2.0913 - val_acc: 0.3035\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 2.0242 - acc: 0.3127 - val_loss: 2.0637 - val_acc: 0.3097\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.0002 - acc: 0.3199 - val_loss: 2.0392 - val_acc: 0.3154\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.9785 - acc: 0.3260 - val_loss: 2.0174 - val_acc: 0.3225\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 1.9598 - acc: 0.3314 - val_loss: 1.9990 - val_acc: 0.3276\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.9431 - acc: 0.3360 - val_loss: 1.9819 - val_acc: 0.3311\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.9279 - acc: 0.3395 - val_loss: 1.9679 - val_acc: 0.3356\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.9124 - acc: 0.3454 - val_loss: 1.9548 - val_acc: 0.3380\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.9008 - acc: 0.3477 - val_loss: 1.9433 - val_acc: 0.3416\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.8878 - acc: 0.3523 - val_loss: 1.9317 - val_acc: 0.3443\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.8756 - acc: 0.3553 - val_loss: 1.9214 - val_acc: 0.3476\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.8647 - acc: 0.3593 - val_loss: 1.9110 - val_acc: 0.3499\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8553 - acc: 0.3613 - val_loss: 1.9021 - val_acc: 0.3538\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.8456 - acc: 0.3639 - val_loss: 1.8938 - val_acc: 0.3545\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.8360 - acc: 0.3666 - val_loss: 1.8858 - val_acc: 0.3570\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 98us/step - loss: 1.8279 - acc: 0.3696 - val_loss: 1.8785 - val_acc: 0.3581\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.8201 - acc: 0.3731 - val_loss: 1.8717 - val_acc: 0.3602\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.8117 - acc: 0.3746 - val_loss: 1.8653 - val_acc: 0.3621\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.8027 - acc: 0.3765 - val_loss: 1.8585 - val_acc: 0.3635\n",
      "Numbers of exp: 13, reduce_factor: 0.40, reduce_patient: 5, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 2.7994 - acc: 0.1341 - val_loss: 2.6045 - val_acc: 0.1764\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.4496 - acc: 0.2011 - val_loss: 2.4227 - val_acc: 0.2131\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.3135 - acc: 0.2323 - val_loss: 2.3196 - val_acc: 0.2347\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 2.2313 - acc: 0.2548 - val_loss: 2.2536 - val_acc: 0.2514\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.1739 - acc: 0.2685 - val_loss: 2.2023 - val_acc: 0.2625\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 2.1306 - acc: 0.2791 - val_loss: 2.1626 - val_acc: 0.2730\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 2.0948 - acc: 0.2884 - val_loss: 2.1320 - val_acc: 0.2808\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.0646 - acc: 0.2981 - val_loss: 2.1056 - val_acc: 0.2877\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.0385 - acc: 0.3040 - val_loss: 2.0811 - val_acc: 0.2958\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 2.0166 - acc: 0.3094 - val_loss: 2.0615 - val_acc: 0.2997\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.9969 - acc: 0.3162 - val_loss: 2.0424 - val_acc: 0.3053\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.9793 - acc: 0.3206 - val_loss: 2.0263 - val_acc: 0.3089\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.9633 - acc: 0.3259 - val_loss: 2.0112 - val_acc: 0.3144\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.9473 - acc: 0.3305 - val_loss: 1.9982 - val_acc: 0.3173\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.9349 - acc: 0.3348 - val_loss: 1.9870 - val_acc: 0.3202\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 1.9212 - acc: 0.3374 - val_loss: 1.9752 - val_acc: 0.3237\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.9093 - acc: 0.3411 - val_loss: 1.9648 - val_acc: 0.3270\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.8979 - acc: 0.3435 - val_loss: 1.9553 - val_acc: 0.3306\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 1.8877 - acc: 0.3474 - val_loss: 1.9458 - val_acc: 0.3324\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 1.8774 - acc: 0.3503 - val_loss: 1.9367 - val_acc: 0.3360\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.8674 - acc: 0.3534 - val_loss: 1.9284 - val_acc: 0.3383\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.8579 - acc: 0.3565 - val_loss: 1.9210 - val_acc: 0.3406\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.8500 - acc: 0.3577 - val_loss: 1.9130 - val_acc: 0.3427\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.8424 - acc: 0.3608 - val_loss: 1.9064 - val_acc: 0.3446\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.8343 - acc: 0.3636 - val_loss: 1.8994 - val_acc: 0.3470\n",
      "Numbers of exp: 14, reduce_factor: 0.40, reduce_patient: 10, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 19s 377us/step - loss: 2.6901 - acc: 0.1572 - val_loss: 2.5236 - val_acc: 0.2120\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 2.3840 - acc: 0.2242 - val_loss: 2.3342 - val_acc: 0.2464\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 2.2665 - acc: 0.2522 - val_loss: 2.2479 - val_acc: 0.2632\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.1945 - acc: 0.2694 - val_loss: 2.1871 - val_acc: 0.2808\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.1409 - acc: 0.2827 - val_loss: 2.1427 - val_acc: 0.2895\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 2.1004 - acc: 0.2947 - val_loss: 2.1054 - val_acc: 0.2970\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 2.0657 - acc: 0.3032 - val_loss: 2.0773 - val_acc: 0.3023\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 2.0387 - acc: 0.3102 - val_loss: 2.0528 - val_acc: 0.3088\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 2.0139 - acc: 0.3175 - val_loss: 2.0315 - val_acc: 0.3151\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.9927 - acc: 0.3249 - val_loss: 2.0136 - val_acc: 0.3170\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.9726 - acc: 0.3305 - val_loss: 1.9995 - val_acc: 0.3221\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.9552 - acc: 0.3335 - val_loss: 1.9836 - val_acc: 0.3260\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9392 - acc: 0.3384 - val_loss: 1.9698 - val_acc: 0.3325\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9256 - acc: 0.3429 - val_loss: 1.9592 - val_acc: 0.3369\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 1.9120 - acc: 0.3464 - val_loss: 1.9478 - val_acc: 0.3375\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.9000 - acc: 0.3498 - val_loss: 1.9364 - val_acc: 0.3414\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.8883 - acc: 0.3539 - val_loss: 1.9273 - val_acc: 0.3439\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8779 - acc: 0.3561 - val_loss: 1.9184 - val_acc: 0.3468\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.8674 - acc: 0.3593 - val_loss: 1.9097 - val_acc: 0.3511\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.8576 - acc: 0.3620 - val_loss: 1.9017 - val_acc: 0.3535\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.8483 - acc: 0.3649 - val_loss: 1.8943 - val_acc: 0.3551\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.8405 - acc: 0.3668 - val_loss: 1.8859 - val_acc: 0.3592\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 5s 92us/step - loss: 1.8314 - acc: 0.3692 - val_loss: 1.8795 - val_acc: 0.3616\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 1.8238 - acc: 0.3722 - val_loss: 1.8730 - val_acc: 0.3636\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.8164 - acc: 0.3740 - val_loss: 1.8669 - val_acc: 0.3651\n",
      "Numbers of exp: 15, reduce_factor: 0.60, reduce_patient: 3, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_75 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 2.6516 - acc: 0.1738 - val_loss: 2.4878 - val_acc: 0.2079\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 2.3387 - acc: 0.2368 - val_loss: 2.3443 - val_acc: 0.2384\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 2.2342 - acc: 0.2634 - val_loss: 2.2624 - val_acc: 0.2572\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 2.1702 - acc: 0.2776 - val_loss: 2.2066 - val_acc: 0.2675\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 2.1232 - acc: 0.2901 - val_loss: 2.1601 - val_acc: 0.2791\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 2.0852 - acc: 0.2986 - val_loss: 2.1246 - val_acc: 0.2866\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 2.0553 - acc: 0.3069 - val_loss: 2.0971 - val_acc: 0.2957\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 2.0289 - acc: 0.3140 - val_loss: 2.0719 - val_acc: 0.3028\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 2.0066 - acc: 0.3187 - val_loss: 2.0522 - val_acc: 0.3077\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.9879 - acc: 0.3250 - val_loss: 2.0363 - val_acc: 0.3118\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9689 - acc: 0.3302 - val_loss: 2.0207 - val_acc: 0.3172\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.9522 - acc: 0.3338 - val_loss: 2.0060 - val_acc: 0.3213\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.9379 - acc: 0.3379 - val_loss: 1.9930 - val_acc: 0.3252\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.9241 - acc: 0.3420 - val_loss: 1.9819 - val_acc: 0.3268\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 1.9118 - acc: 0.3458 - val_loss: 1.9707 - val_acc: 0.3309\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.9006 - acc: 0.3493 - val_loss: 1.9605 - val_acc: 0.3334\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.8888 - acc: 0.3525 - val_loss: 1.9512 - val_acc: 0.3351\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.8783 - acc: 0.3549 - val_loss: 1.9421 - val_acc: 0.3382\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.8688 - acc: 0.3584 - val_loss: 1.9337 - val_acc: 0.3403\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.8592 - acc: 0.3605 - val_loss: 1.9267 - val_acc: 0.3421\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 1.8503 - acc: 0.3635 - val_loss: 1.9200 - val_acc: 0.3433\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.8427 - acc: 0.3662 - val_loss: 1.9131 - val_acc: 0.3467\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.8346 - acc: 0.3697 - val_loss: 1.9074 - val_acc: 0.3478\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.8268 - acc: 0.3712 - val_loss: 1.9000 - val_acc: 0.3494\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.8191 - acc: 0.3730 - val_loss: 1.8942 - val_acc: 0.3520\n",
      "Numbers of exp: 16, reduce_factor: 0.60, reduce_patient: 5, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 2.6902 - acc: 0.1595 - val_loss: 2.6366 - val_acc: 0.1842\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 2.3569 - acc: 0.2296 - val_loss: 2.3304 - val_acc: 0.2339\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 2.2463 - acc: 0.2552 - val_loss: 2.2263 - val_acc: 0.2561\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 2.1776 - acc: 0.2722 - val_loss: 2.1731 - val_acc: 0.2709\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 2.1290 - acc: 0.2828 - val_loss: 2.1312 - val_acc: 0.2836\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 2.0911 - acc: 0.2933 - val_loss: 2.0998 - val_acc: 0.2893\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 2.0600 - acc: 0.3013 - val_loss: 2.0758 - val_acc: 0.2967\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 2.0345 - acc: 0.3077 - val_loss: 2.0555 - val_acc: 0.3050\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.0119 - acc: 0.3142 - val_loss: 2.0386 - val_acc: 0.3084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.9912 - acc: 0.3192 - val_loss: 2.0207 - val_acc: 0.3121\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 1.9745 - acc: 0.3233 - val_loss: 2.0058 - val_acc: 0.3157\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.9581 - acc: 0.3302 - val_loss: 1.9915 - val_acc: 0.3205\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.9433 - acc: 0.3325 - val_loss: 1.9798 - val_acc: 0.3237\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 1.9298 - acc: 0.3368 - val_loss: 1.9687 - val_acc: 0.3269\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 1.9174 - acc: 0.3402 - val_loss: 1.9587 - val_acc: 0.3316\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.9059 - acc: 0.3422 - val_loss: 1.9483 - val_acc: 0.3347\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 1.8943 - acc: 0.3468 - val_loss: 1.9389 - val_acc: 0.3359\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.8851 - acc: 0.3509 - val_loss: 1.9302 - val_acc: 0.3377\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.8748 - acc: 0.3520 - val_loss: 1.9221 - val_acc: 0.3418\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.8656 - acc: 0.3538 - val_loss: 1.9142 - val_acc: 0.3432\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 1.8575 - acc: 0.3571 - val_loss: 1.9068 - val_acc: 0.3467\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 1.8490 - acc: 0.3592 - val_loss: 1.9002 - val_acc: 0.3478\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.8416 - acc: 0.3605 - val_loss: 1.8940 - val_acc: 0.3492\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 1.8331 - acc: 0.3640 - val_loss: 1.8877 - val_acc: 0.3514\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.8255 - acc: 0.3662 - val_loss: 1.8815 - val_acc: 0.3527\n",
      "Numbers of exp: 17, reduce_factor: 0.60, reduce_patient: 10, <keras.optimizers.Adam object at 0xb4013ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 2.6727 - acc: 0.1599 - val_loss: 2.5459 - val_acc: 0.2132\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.3428 - acc: 0.2311 - val_loss: 2.3489 - val_acc: 0.2420\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.2282 - acc: 0.2608 - val_loss: 2.2447 - val_acc: 0.2627\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.1581 - acc: 0.2792 - val_loss: 2.1792 - val_acc: 0.2762\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.1089 - acc: 0.2921 - val_loss: 2.1302 - val_acc: 0.2869\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.0709 - acc: 0.3019 - val_loss: 2.0940 - val_acc: 0.2977\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.0405 - acc: 0.3107 - val_loss: 2.0660 - val_acc: 0.3055\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.0135 - acc: 0.3170 - val_loss: 2.0427 - val_acc: 0.3112\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9920 - acc: 0.3231 - val_loss: 2.0224 - val_acc: 0.3163\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.9726 - acc: 0.3274 - val_loss: 2.0053 - val_acc: 0.3215\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.9545 - acc: 0.3328 - val_loss: 1.9896 - val_acc: 0.3252\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.9374 - acc: 0.3378 - val_loss: 1.9757 - val_acc: 0.3306\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.9240 - acc: 0.3407 - val_loss: 1.9627 - val_acc: 0.3332\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.9105 - acc: 0.3444 - val_loss: 1.9513 - val_acc: 0.3354\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8980 - acc: 0.3472 - val_loss: 1.9403 - val_acc: 0.3384\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.8867 - acc: 0.3516 - val_loss: 1.9303 - val_acc: 0.3420\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.8757 - acc: 0.3544 - val_loss: 1.9207 - val_acc: 0.3447\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8653 - acc: 0.3575 - val_loss: 1.9117 - val_acc: 0.3453\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8559 - acc: 0.3617 - val_loss: 1.9047 - val_acc: 0.3473\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.8469 - acc: 0.3634 - val_loss: 1.8963 - val_acc: 0.3486\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 1.8378 - acc: 0.3651 - val_loss: 1.8898 - val_acc: 0.3516\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.8295 - acc: 0.3680 - val_loss: 1.8827 - val_acc: 0.3509\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.8205 - acc: 0.3705 - val_loss: 1.8755 - val_acc: 0.3533\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.8126 - acc: 0.3724 - val_loss: 1.8697 - val_acc: 0.3542\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.8069 - acc: 0.3745 - val_loss: 1.8632 - val_acc: 0.3572\n",
      "Numbers of exp: 18, reduce_factor: 0.20, reduce_patient: 3, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_78 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.8407 - acc: 0.3683 - val_loss: 1.9270 - val_acc: 0.3362\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.5429 - acc: 0.4542 - val_loss: 2.3127 - val_acc: 0.2886\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4324 - acc: 0.4931 - val_loss: 1.8992 - val_acc: 0.3522\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.3470 - acc: 0.5228 - val_loss: 2.1128 - val_acc: 0.3165\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.2800 - acc: 0.5488 - val_loss: 1.8292 - val_acc: 0.3771\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.2337 - acc: 0.5627 - val_loss: 2.3810 - val_acc: 0.3220\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.1790 - acc: 0.5843 - val_loss: 2.4753 - val_acc: 0.3155\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.1382 - acc: 0.5994 - val_loss: 1.6735 - val_acc: 0.4210\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.0933 - acc: 0.6135 - val_loss: 1.9393 - val_acc: 0.3889\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.0544 - acc: 0.6290 - val_loss: 2.1261 - val_acc: 0.3545\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.0174 - acc: 0.6430 - val_loss: 1.8625 - val_acc: 0.3922\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 0.8667 - acc: 0.7036 - val_loss: 1.3453 - val_acc: 0.5285\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 0.8308 - acc: 0.7192 - val_loss: 1.3335 - val_acc: 0.5286\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 0.8086 - acc: 0.7268 - val_loss: 1.3445 - val_acc: 0.5327\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.7886 - acc: 0.7347 - val_loss: 1.3336 - val_acc: 0.5329\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 5s 106us/step - loss: 0.7699 - acc: 0.7418 - val_loss: 1.3466 - val_acc: 0.5351\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.7335 - acc: 0.7576 - val_loss: 1.3012 - val_acc: 0.5484\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.7252 - acc: 0.7619 - val_loss: 1.3077 - val_acc: 0.5461\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.7217 - acc: 0.7634 - val_loss: 1.3083 - val_acc: 0.5470\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 0.7160 - acc: 0.7659 - val_loss: 1.3114 - val_acc: 0.5466\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7078 - acc: 0.7686 - val_loss: 1.3108 - val_acc: 0.5481\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 0.7058 - acc: 0.7705 - val_loss: 1.3114 - val_acc: 0.5481\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.7060 - acc: 0.7709 - val_loss: 1.3127 - val_acc: 0.5479\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 0.7034 - acc: 0.7721 - val_loss: 1.3133 - val_acc: 0.5492\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 0.7033 - acc: 0.7718 - val_loss: 1.3138 - val_acc: 0.5484\n",
      "Numbers of exp: 19, reduce_factor: 0.20, reduce_patient: 5, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_235 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_236 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_237 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 26s 516us/step - loss: 2.9184 - acc: 0.1114 - val_loss: 2.8425 - val_acc: 0.1222\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 2.7683 - acc: 0.1360 - val_loss: 2.7306 - val_acc: 0.1468\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.6523 - acc: 0.1576 - val_loss: 2.6464 - val_acc: 0.1678\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.5625 - acc: 0.1757 - val_loss: 2.5736 - val_acc: 0.1855\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.4894 - acc: 0.1927 - val_loss: 2.5053 - val_acc: 0.1980\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.4296 - acc: 0.2060 - val_loss: 2.4440 - val_acc: 0.2094\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.3778 - acc: 0.2177 - val_loss: 2.3929 - val_acc: 0.2187\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.3340 - acc: 0.2265 - val_loss: 2.3506 - val_acc: 0.2285\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.2935 - acc: 0.2372 - val_loss: 2.3117 - val_acc: 0.2370\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.2590 - acc: 0.2453 - val_loss: 2.2778 - val_acc: 0.2462\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.2267 - acc: 0.2541 - val_loss: 2.2499 - val_acc: 0.2541\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.1977 - acc: 0.2599 - val_loss: 2.2229 - val_acc: 0.2612\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.1706 - acc: 0.2676 - val_loss: 2.1982 - val_acc: 0.2671\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.1468 - acc: 0.2736 - val_loss: 2.1750 - val_acc: 0.2703\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 2.1229 - acc: 0.2797 - val_loss: 2.1544 - val_acc: 0.2754\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 2.1031 - acc: 0.2838 - val_loss: 2.1357 - val_acc: 0.2804\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 2.0819 - acc: 0.2904 - val_loss: 2.1176 - val_acc: 0.2834\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 2.0648 - acc: 0.2952 - val_loss: 2.1009 - val_acc: 0.2863\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 2.0464 - acc: 0.3001 - val_loss: 2.0851 - val_acc: 0.2912\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 2.0309 - acc: 0.3050 - val_loss: 2.0706 - val_acc: 0.2949\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 83us/step - loss: 2.0156 - acc: 0.3099 - val_loss: 2.0577 - val_acc: 0.3005\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 2.0013 - acc: 0.3138 - val_loss: 2.0447 - val_acc: 0.3051\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.9872 - acc: 0.3181 - val_loss: 2.0319 - val_acc: 0.3098\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 1.9749 - acc: 0.3230 - val_loss: 2.0210 - val_acc: 0.3126\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 102us/step - loss: 1.9634 - acc: 0.3240 - val_loss: 2.0095 - val_acc: 0.3143\n",
      "Numbers of exp: 20, reduce_factor: 0.20, reduce_patient: 10, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 2.9131 - acc: 0.1280 - val_loss: 2.7962 - val_acc: 0.1437\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.7734 - acc: 0.1462 - val_loss: 2.6871 - val_acc: 0.1685\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.6628 - acc: 0.1640 - val_loss: 2.6096 - val_acc: 0.1903\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.5727 - acc: 0.1838 - val_loss: 2.5469 - val_acc: 0.2051\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.4989 - acc: 0.1998 - val_loss: 2.4899 - val_acc: 0.2183\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 2.4402 - acc: 0.2148 - val_loss: 2.4359 - val_acc: 0.2294\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.3897 - acc: 0.2259 - val_loss: 2.3888 - val_acc: 0.2368\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 101us/step - loss: 2.3459 - acc: 0.2368 - val_loss: 2.3472 - val_acc: 0.2473\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.3077 - acc: 0.2454 - val_loss: 2.3101 - val_acc: 0.2550\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.2728 - acc: 0.2524 - val_loss: 2.2772 - val_acc: 0.2600\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.2418 - acc: 0.2602 - val_loss: 2.2485 - val_acc: 0.2672\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.2127 - acc: 0.2650 - val_loss: 2.2225 - val_acc: 0.2726\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.1862 - acc: 0.2732 - val_loss: 2.1997 - val_acc: 0.2775\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 2.1614 - acc: 0.2790 - val_loss: 2.1771 - val_acc: 0.2816\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.1399 - acc: 0.2848 - val_loss: 2.1554 - val_acc: 0.2863\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 2.1179 - acc: 0.2898 - val_loss: 2.1359 - val_acc: 0.2922\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.0989 - acc: 0.2950 - val_loss: 2.1193 - val_acc: 0.2974\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 2.0804 - acc: 0.2994 - val_loss: 2.1042 - val_acc: 0.2999\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.0631 - acc: 0.3043 - val_loss: 2.0887 - val_acc: 0.3043\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 2.0474 - acc: 0.3084 - val_loss: 2.0748 - val_acc: 0.3078\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 2.0321 - acc: 0.3118 - val_loss: 2.0621 - val_acc: 0.3106\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 2.0181 - acc: 0.3164 - val_loss: 2.0503 - val_acc: 0.3122\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 2.0047 - acc: 0.3208 - val_loss: 2.0377 - val_acc: 0.3172\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.9920 - acc: 0.3243 - val_loss: 2.0266 - val_acc: 0.3218\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.9794 - acc: 0.3267 - val_loss: 2.0148 - val_acc: 0.3241\n",
      "Numbers of exp: 21, reduce_factor: 0.40, reduce_patient: 3, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_81 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 2.8673 - acc: 0.1257 - val_loss: 2.7622 - val_acc: 0.1485\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.7396 - acc: 0.1468 - val_loss: 2.6570 - val_acc: 0.1729\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.6396 - acc: 0.1664 - val_loss: 2.5754 - val_acc: 0.1889\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.5591 - acc: 0.1826 - val_loss: 2.5097 - val_acc: 0.2037\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.4904 - acc: 0.1979 - val_loss: 2.4501 - val_acc: 0.2168\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 2.4321 - acc: 0.2127 - val_loss: 2.3984 - val_acc: 0.2271\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 2.3813 - acc: 0.2240 - val_loss: 2.3535 - val_acc: 0.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.3368 - acc: 0.2346 - val_loss: 2.3146 - val_acc: 0.2481\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.2967 - acc: 0.2431 - val_loss: 2.2808 - val_acc: 0.2575\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.2621 - acc: 0.2516 - val_loss: 2.2496 - val_acc: 0.2637\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 2.2299 - acc: 0.2596 - val_loss: 2.2212 - val_acc: 0.2710\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 2.2005 - acc: 0.2677 - val_loss: 2.1946 - val_acc: 0.2753\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.1743 - acc: 0.2738 - val_loss: 2.1724 - val_acc: 0.2797\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 2.1488 - acc: 0.2804 - val_loss: 2.1500 - val_acc: 0.2846\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 2.1270 - acc: 0.2856 - val_loss: 2.1310 - val_acc: 0.2893\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 2.1066 - acc: 0.2914 - val_loss: 2.1126 - val_acc: 0.2936\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 2.0849 - acc: 0.2970 - val_loss: 2.0945 - val_acc: 0.2982\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.0689 - acc: 0.3016 - val_loss: 2.0786 - val_acc: 0.3033\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.0507 - acc: 0.3064 - val_loss: 2.0640 - val_acc: 0.3070\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.0356 - acc: 0.3106 - val_loss: 2.0492 - val_acc: 0.3109\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.0201 - acc: 0.3149 - val_loss: 2.0367 - val_acc: 0.3140\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.0057 - acc: 0.3184 - val_loss: 2.0247 - val_acc: 0.3185\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.9919 - acc: 0.3216 - val_loss: 2.0132 - val_acc: 0.3233\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 1.9793 - acc: 0.3268 - val_loss: 2.0024 - val_acc: 0.3262\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 1.9667 - acc: 0.3310 - val_loss: 1.9915 - val_acc: 0.3299\n",
      "Numbers of exp: 22, reduce_factor: 0.40, reduce_patient: 5, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_82 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_244 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_245 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_246 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 3.0938 - acc: 0.0934 - val_loss: 2.9706 - val_acc: 0.1086\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.9374 - acc: 0.1108 - val_loss: 2.8413 - val_acc: 0.1327\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.8124 - acc: 0.1303 - val_loss: 2.7432 - val_acc: 0.1527\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 2.7085 - acc: 0.1482 - val_loss: 2.6613 - val_acc: 0.1702\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 2.6217 - acc: 0.1668 - val_loss: 2.5904 - val_acc: 0.1866\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 2.5506 - acc: 0.1816 - val_loss: 2.5309 - val_acc: 0.1984\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 2.4893 - acc: 0.1958 - val_loss: 2.4803 - val_acc: 0.2078\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.4361 - acc: 0.2078 - val_loss: 2.4338 - val_acc: 0.2171\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.3880 - acc: 0.2185 - val_loss: 2.3926 - val_acc: 0.2261\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 2.3459 - acc: 0.2289 - val_loss: 2.3553 - val_acc: 0.2329\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.3100 - acc: 0.2383 - val_loss: 2.3223 - val_acc: 0.2415\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 2.2752 - acc: 0.2469 - val_loss: 2.2909 - val_acc: 0.2472\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.2434 - acc: 0.2538 - val_loss: 2.2634 - val_acc: 0.2554\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.2151 - acc: 0.2623 - val_loss: 2.2377 - val_acc: 0.2621\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 2.1894 - acc: 0.2667 - val_loss: 2.2150 - val_acc: 0.2692\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.1657 - acc: 0.2738 - val_loss: 2.1931 - val_acc: 0.2752\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 2.1432 - acc: 0.2801 - val_loss: 2.1727 - val_acc: 0.2824\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.1218 - acc: 0.2863 - val_loss: 2.1543 - val_acc: 0.2864\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 2.1032 - acc: 0.2904 - val_loss: 2.1361 - val_acc: 0.2910\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 2.0850 - acc: 0.2957 - val_loss: 2.1203 - val_acc: 0.2932\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.0677 - acc: 0.3009 - val_loss: 2.1044 - val_acc: 0.2986\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 2.0511 - acc: 0.3048 - val_loss: 2.0911 - val_acc: 0.3007\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.0366 - acc: 0.3097 - val_loss: 2.0769 - val_acc: 0.3022\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 2.0208 - acc: 0.3134 - val_loss: 2.0634 - val_acc: 0.3075\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.0077 - acc: 0.3177 - val_loss: 2.0519 - val_acc: 0.3122\n",
      "Numbers of exp: 23, reduce_factor: 0.40, reduce_patient: 10, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_247 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 2.9101 - acc: 0.1029 - val_loss: 2.8193 - val_acc: 0.1228\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.7651 - acc: 0.1271 - val_loss: 2.7127 - val_acc: 0.1496\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.6514 - acc: 0.1517 - val_loss: 2.6297 - val_acc: 0.1726\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.5604 - acc: 0.1724 - val_loss: 2.5539 - val_acc: 0.1871\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.4856 - acc: 0.1917 - val_loss: 2.4910 - val_acc: 0.2002\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.4222 - acc: 0.2083 - val_loss: 2.4333 - val_acc: 0.2116\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.3686 - acc: 0.2217 - val_loss: 2.3827 - val_acc: 0.2244\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 2.3233 - acc: 0.2321 - val_loss: 2.3389 - val_acc: 0.2359\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 2.2817 - acc: 0.2414 - val_loss: 2.2979 - val_acc: 0.2446\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 2.2469 - acc: 0.2514 - val_loss: 2.2641 - val_acc: 0.2534\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.2147 - acc: 0.2597 - val_loss: 2.2328 - val_acc: 0.2611\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.1849 - acc: 0.2680 - val_loss: 2.2058 - val_acc: 0.2680\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.1578 - acc: 0.2750 - val_loss: 2.1816 - val_acc: 0.2739\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 2.1326 - acc: 0.2818 - val_loss: 2.1578 - val_acc: 0.2802\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.1095 - acc: 0.2882 - val_loss: 2.1367 - val_acc: 0.2862\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 2.0892 - acc: 0.2932 - val_loss: 2.1174 - val_acc: 0.2924\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 2.0695 - acc: 0.2988 - val_loss: 2.1000 - val_acc: 0.2935\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 2.0504 - acc: 0.3036 - val_loss: 2.0837 - val_acc: 0.2996\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 2.0346 - acc: 0.3070 - val_loss: 2.0693 - val_acc: 0.3034\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.0176 - acc: 0.3131 - val_loss: 2.0556 - val_acc: 0.3062\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.0033 - acc: 0.3167 - val_loss: 2.0421 - val_acc: 0.3099\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.9882 - acc: 0.3201 - val_loss: 2.0302 - val_acc: 0.3134\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.9765 - acc: 0.3249 - val_loss: 2.0187 - val_acc: 0.3181\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.9621 - acc: 0.3295 - val_loss: 2.0083 - val_acc: 0.3205\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.9505 - acc: 0.3332 - val_loss: 1.9977 - val_acc: 0.3227\n",
      "Numbers of exp: 24, reduce_factor: 0.60, reduce_patient: 3, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_84 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_252 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 2.9268 - acc: 0.1243 - val_loss: 2.8588 - val_acc: 0.1415\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.7885 - acc: 0.1486 - val_loss: 2.7531 - val_acc: 0.1566\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.6792 - acc: 0.1667 - val_loss: 2.6674 - val_acc: 0.1747\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 2.5909 - acc: 0.1840 - val_loss: 2.5900 - val_acc: 0.1896\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 5s 103us/step - loss: 2.5160 - acc: 0.1985 - val_loss: 2.5241 - val_acc: 0.2023\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 2.4511 - acc: 0.2117 - val_loss: 2.4658 - val_acc: 0.2140\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.3957 - acc: 0.2217 - val_loss: 2.4142 - val_acc: 0.2230\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 2.3484 - acc: 0.2324 - val_loss: 2.3682 - val_acc: 0.2328\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 97us/step - loss: 2.3060 - acc: 0.2416 - val_loss: 2.3292 - val_acc: 0.2410\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.2696 - acc: 0.2501 - val_loss: 2.2918 - val_acc: 0.2482\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 2.2359 - acc: 0.2584 - val_loss: 2.2607 - val_acc: 0.2550\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.2061 - acc: 0.2649 - val_loss: 2.2307 - val_acc: 0.2621\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.1790 - acc: 0.2709 - val_loss: 2.2038 - val_acc: 0.2692\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.1522 - acc: 0.2783 - val_loss: 2.1794 - val_acc: 0.2730\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.1293 - acc: 0.2849 - val_loss: 2.1562 - val_acc: 0.2784\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 2.1084 - acc: 0.2889 - val_loss: 2.1364 - val_acc: 0.2849\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 2.0883 - acc: 0.2933 - val_loss: 2.1167 - val_acc: 0.2895\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 2.0709 - acc: 0.2986 - val_loss: 2.1004 - val_acc: 0.2940\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 2.0531 - acc: 0.3020 - val_loss: 2.0849 - val_acc: 0.2988\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 2.0373 - acc: 0.3075 - val_loss: 2.0697 - val_acc: 0.3033\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 2.0211 - acc: 0.3110 - val_loss: 2.0556 - val_acc: 0.3078\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 2.0069 - acc: 0.3142 - val_loss: 2.0430 - val_acc: 0.3119\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.9923 - acc: 0.3189 - val_loss: 2.0304 - val_acc: 0.3159\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 1.9803 - acc: 0.3240 - val_loss: 2.0185 - val_acc: 0.3179\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 90us/step - loss: 1.9685 - acc: 0.3271 - val_loss: 2.0067 - val_acc: 0.3194\n",
      "Numbers of exp: 25, reduce_factor: 0.60, reduce_patient: 5, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_85 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_253 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_254 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_255 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 3.0243 - acc: 0.0935 - val_loss: 2.9460 - val_acc: 0.1111\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 2.8684 - acc: 0.1157 - val_loss: 2.8256 - val_acc: 0.1325\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 4s 89us/step - loss: 2.7497 - acc: 0.1386 - val_loss: 2.7272 - val_acc: 0.1542\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.6510 - acc: 0.1576 - val_loss: 2.6413 - val_acc: 0.1673\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 4s 87us/step - loss: 2.5705 - acc: 0.1752 - val_loss: 2.5669 - val_acc: 0.1820\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.5035 - acc: 0.1879 - val_loss: 2.5052 - val_acc: 0.1953\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.4459 - acc: 0.2022 - val_loss: 2.4540 - val_acc: 0.2081\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 2.3975 - acc: 0.2135 - val_loss: 2.4090 - val_acc: 0.2153\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.3544 - acc: 0.2228 - val_loss: 2.3678 - val_acc: 0.2215\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.3166 - acc: 0.2341 - val_loss: 2.3349 - val_acc: 0.2314\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.2834 - acc: 0.2425 - val_loss: 2.3051 - val_acc: 0.2356\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 5s 104us/step - loss: 2.2538 - acc: 0.2489 - val_loss: 2.2790 - val_acc: 0.2429\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.2263 - acc: 0.2573 - val_loss: 2.2534 - val_acc: 0.2507\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 2.2002 - acc: 0.2629 - val_loss: 2.2297 - val_acc: 0.2575\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 2.1777 - acc: 0.2687 - val_loss: 2.2093 - val_acc: 0.2638\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 2.1555 - acc: 0.2755 - val_loss: 2.1919 - val_acc: 0.2679\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.1346 - acc: 0.2804 - val_loss: 2.1732 - val_acc: 0.2729\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 2.1163 - acc: 0.2859 - val_loss: 2.1561 - val_acc: 0.2769\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 2.0983 - acc: 0.2909 - val_loss: 2.1424 - val_acc: 0.2808\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 90us/step - loss: 2.0813 - acc: 0.2938 - val_loss: 2.1275 - val_acc: 0.2832\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.0661 - acc: 0.3000 - val_loss: 2.1130 - val_acc: 0.2877\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 5s 91us/step - loss: 2.0508 - acc: 0.3027 - val_loss: 2.0998 - val_acc: 0.2912\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 2.0361 - acc: 0.3068 - val_loss: 2.0876 - val_acc: 0.2947\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 2.0229 - acc: 0.3097 - val_loss: 2.0767 - val_acc: 0.2970\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.0098 - acc: 0.3148 - val_loss: 2.0651 - val_acc: 0.2997\n",
      "Numbers of exp: 26, reduce_factor: 0.60, reduce_patient: 10, <keras.optimizers.RMSprop object at 0xbf3898438>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_86 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 922,378\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 25s 491us/step - loss: 3.1115 - acc: 0.0998 - val_loss: 3.0293 - val_acc: 0.1095\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 2.9437 - acc: 0.1176 - val_loss: 2.9036 - val_acc: 0.1419\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.8082 - acc: 0.1409 - val_loss: 2.8046 - val_acc: 0.1681\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.6994 - acc: 0.1632 - val_loss: 2.7188 - val_acc: 0.1865\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 2.6112 - acc: 0.1837 - val_loss: 2.6319 - val_acc: 0.2030\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 2.5399 - acc: 0.1988 - val_loss: 2.5556 - val_acc: 0.2156\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 2.4793 - acc: 0.2128 - val_loss: 2.4927 - val_acc: 0.2270\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.4266 - acc: 0.2229 - val_loss: 2.4403 - val_acc: 0.2329\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 110us/step - loss: 2.3804 - acc: 0.2336 - val_loss: 2.3937 - val_acc: 0.2426\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 2.3386 - acc: 0.2429 - val_loss: 2.3529 - val_acc: 0.2486\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 2.3019 - acc: 0.2492 - val_loss: 2.3180 - val_acc: 0.2552\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 2.2682 - acc: 0.2576 - val_loss: 2.2852 - val_acc: 0.2615\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 2.2374 - acc: 0.2643 - val_loss: 2.2572 - val_acc: 0.2696\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 2.2085 - acc: 0.2699 - val_loss: 2.2324 - val_acc: 0.2748\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 5s 100us/step - loss: 2.1820 - acc: 0.2759 - val_loss: 2.2100 - val_acc: 0.2768\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.1577 - acc: 0.2817 - val_loss: 2.1887 - val_acc: 0.2811\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 2.1355 - acc: 0.2881 - val_loss: 2.1698 - val_acc: 0.2843\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 5s 99us/step - loss: 2.1158 - acc: 0.2916 - val_loss: 2.1516 - val_acc: 0.2895\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.0953 - acc: 0.2968 - val_loss: 2.1356 - val_acc: 0.2914\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 2.0775 - acc: 0.3000 - val_loss: 2.1197 - val_acc: 0.2963\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 2.0612 - acc: 0.3038 - val_loss: 2.1053 - val_acc: 0.2983\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.0457 - acc: 0.3075 - val_loss: 2.0904 - val_acc: 0.3024\n",
      "Epoch 23/25\n",
      "29696/50000 [================>.............] - ETA: 2s - loss: 2.0340 - acc: 0.3136"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "results = {}\n",
    "for i, (optim, reduce_factor, reduce_patient) in enumerate(itertools.product(optimizer_set, reduce_lr_factor, redice_lr_patient)):\n",
    "    print(\"Numbers of exp: %i, reduce_factor: %.2f, reduce_patient: %i, %s\" % (i, reduce_factor, reduce_patient, str(optim)))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optim)\n",
    "    \n",
    "    \"\"\"Code Here\n",
    "    設定 reduce learning rate 的 callback function\n",
    "    \"\"\"\n",
    "    reduce_lr = ReduceLROnPlateau(factor= reduce_factor, \n",
    "                              min_lr=1e-12, \n",
    "                              monitor='val_loss', \n",
    "                              patience= reduce_patient, \n",
    "                              verbose=1)\n",
    "    \n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True,\n",
    "              callbacks=[reduce_lr]\n",
    "             )\n",
    "\n",
    "    # Collect results\n",
    "    exp_name_tag = (\"%s,%s,rf=%s,rp=%s \" % (i,str(optim),reduce_factor, reduce_patient))\n",
    "    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n",
    "                             'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             'train-acc': model.history.history[\"acc\"],\n",
    "                             'valid-acc': model.history.history[\"val_acc\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "NUM_COLORS = len(results.keys())\n",
    "\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=NUM_COLORS-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "color_bar = [scalarMap.to_rgba(i) for i in range(NUM_COLORS)]\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
