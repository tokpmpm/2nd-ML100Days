{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "### 請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "def build_mlp_before(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = BatchNormalization()(input_layer)\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            \n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            \n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "def build_mlp_dropout(input_shape, output_units=10, num_neurons=[512, 256, 128], drp_ratio=0.2):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = Dropout(drp_ratio)(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = Dropout(drp_ratio)(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "def build_mlp_l1(input_shape, output_units=10, num_neurons=[512, 256, 128], l2_ratio=1e-8):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1), \n",
    "                                   kernel_regularizer=l1(l2_ratio))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=l1(l2_ratio))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code Here\n",
    "設定超參數\n",
    "\"\"\"\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 2.1660 - acc: 0.2038 - val_loss: 1.9701 - val_acc: 0.3095\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.9688 - acc: 0.2820 - val_loss: 1.8560 - val_acc: 0.3490\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.8878 - acc: 0.3178 - val_loss: 1.7877 - val_acc: 0.3746\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.8325 - acc: 0.3431 - val_loss: 1.7390 - val_acc: 0.3870\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.7911 - acc: 0.3597 - val_loss: 1.6936 - val_acc: 0.4048\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.7552 - acc: 0.3697 - val_loss: 1.6610 - val_acc: 0.4153\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.7210 - acc: 0.3839 - val_loss: 1.6307 - val_acc: 0.4226\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.6972 - acc: 0.3937 - val_loss: 1.6113 - val_acc: 0.4312\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.6723 - acc: 0.4036 - val_loss: 1.5847 - val_acc: 0.4424\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.6511 - acc: 0.4151 - val_loss: 1.5624 - val_acc: 0.4477\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.6295 - acc: 0.4232 - val_loss: 1.5481 - val_acc: 0.4485\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.6114 - acc: 0.4272 - val_loss: 1.5312 - val_acc: 0.4586\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5949 - acc: 0.4343 - val_loss: 1.5149 - val_acc: 0.4600\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.5800 - acc: 0.4383 - val_loss: 1.4968 - val_acc: 0.4686\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.5624 - acc: 0.4466 - val_loss: 1.4901 - val_acc: 0.4708\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5490 - acc: 0.4499 - val_loss: 1.4808 - val_acc: 0.4715\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.5340 - acc: 0.4559 - val_loss: 1.4679 - val_acc: 0.4777\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.5235 - acc: 0.4609 - val_loss: 1.4532 - val_acc: 0.4801\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.5063 - acc: 0.4647 - val_loss: 1.4437 - val_acc: 0.4851\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.4991 - acc: 0.4659 - val_loss: 1.4382 - val_acc: 0.4900\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.4846 - acc: 0.4717 - val_loss: 1.4387 - val_acc: 0.4877\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.4739 - acc: 0.4761 - val_loss: 1.4299 - val_acc: 0.4922\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.4595 - acc: 0.4811 - val_loss: 1.4144 - val_acc: 0.4953\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.4493 - acc: 0.4855 - val_loss: 1.4107 - val_acc: 0.4982\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.4431 - acc: 0.4866 - val_loss: 1.4106 - val_acc: 0.4958\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.4264 - acc: 0.4947 - val_loss: 1.3992 - val_acc: 0.5013\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.4183 - acc: 0.4971 - val_loss: 1.3909 - val_acc: 0.5021\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.4114 - acc: 0.4959 - val_loss: 1.3855 - val_acc: 0.5036\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.4004 - acc: 0.5030 - val_loss: 1.3792 - val_acc: 0.5080\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.3838 - acc: 0.5090 - val_loss: 1.3677 - val_acc: 0.5109\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.3829 - acc: 0.5063 - val_loss: 1.3590 - val_acc: 0.5140\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.3721 - acc: 0.5116 - val_loss: 1.3564 - val_acc: 0.5137\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.3657 - acc: 0.5156 - val_loss: 1.3549 - val_acc: 0.5148\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.3583 - acc: 0.5147 - val_loss: 1.3487 - val_acc: 0.5180\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.3509 - acc: 0.5175 - val_loss: 1.3435 - val_acc: 0.5197\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.3372 - acc: 0.5223 - val_loss: 1.3454 - val_acc: 0.5167\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.3297 - acc: 0.5255 - val_loss: 1.3374 - val_acc: 0.5191\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.3234 - acc: 0.5289 - val_loss: 1.3376 - val_acc: 0.5220\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.3149 - acc: 0.5338 - val_loss: 1.3423 - val_acc: 0.5226\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.3102 - acc: 0.5313 - val_loss: 1.3462 - val_acc: 0.5162\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.3007 - acc: 0.5379 - val_loss: 1.3294 - val_acc: 0.5273\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2967 - acc: 0.5401 - val_loss: 1.3212 - val_acc: 0.5262\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2904 - acc: 0.5392 - val_loss: 1.3131 - val_acc: 0.5287\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2803 - acc: 0.5454 - val_loss: 1.3203 - val_acc: 0.5236\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2766 - acc: 0.5453 - val_loss: 1.3209 - val_acc: 0.5241\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.2709 - acc: 0.5454 - val_loss: 1.3151 - val_acc: 0.5290\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2602 - acc: 0.5505 - val_loss: 1.3057 - val_acc: 0.5333\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2526 - acc: 0.5541 - val_loss: 1.3072 - val_acc: 0.5295\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.2440 - acc: 0.5558 - val_loss: 1.3077 - val_acc: 0.5291\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.2360 - acc: 0.5572 - val_loss: 1.3082 - val_acc: 0.5321\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 2.0301 - acc: 0.2797 - val_loss: 1.8693 - val_acc: 0.3352\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8136 - acc: 0.3630 - val_loss: 1.7738 - val_acc: 0.3788\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.7343 - acc: 0.3917 - val_loss: 1.7003 - val_acc: 0.3994\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.6727 - acc: 0.4141 - val_loss: 1.6562 - val_acc: 0.4210\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6218 - acc: 0.4328 - val_loss: 1.6062 - val_acc: 0.4455\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5816 - acc: 0.4466 - val_loss: 1.5748 - val_acc: 0.4509\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5456 - acc: 0.4602 - val_loss: 1.5435 - val_acc: 0.4596\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5130 - acc: 0.4708 - val_loss: 1.5134 - val_acc: 0.4728\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.4843 - acc: 0.4785 - val_loss: 1.5014 - val_acc: 0.4697\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.4578 - acc: 0.4894 - val_loss: 1.4874 - val_acc: 0.4740\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.4322 - acc: 0.4969 - val_loss: 1.4600 - val_acc: 0.4859\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4087 - acc: 0.5072 - val_loss: 1.4574 - val_acc: 0.4797\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3850 - acc: 0.5123 - val_loss: 1.4424 - val_acc: 0.4895\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3658 - acc: 0.5193 - val_loss: 1.4406 - val_acc: 0.4873\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3441 - acc: 0.5267 - val_loss: 1.4269 - val_acc: 0.4933\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3243 - acc: 0.5342 - val_loss: 1.3992 - val_acc: 0.5025\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3073 - acc: 0.5408 - val_loss: 1.3991 - val_acc: 0.5021\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.2884 - acc: 0.5456 - val_loss: 1.3852 - val_acc: 0.5065\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2731 - acc: 0.5522 - val_loss: 1.3943 - val_acc: 0.5073\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2551 - acc: 0.5570 - val_loss: 1.3910 - val_acc: 0.5116\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2419 - acc: 0.5628 - val_loss: 1.3687 - val_acc: 0.5140\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.2218 - acc: 0.5708 - val_loss: 1.3563 - val_acc: 0.5194\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2090 - acc: 0.5762 - val_loss: 1.3566 - val_acc: 0.5195\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.1933 - acc: 0.5815 - val_loss: 1.3978 - val_acc: 0.5066\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.1825 - acc: 0.5839 - val_loss: 1.3509 - val_acc: 0.5243\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.1666 - acc: 0.5867 - val_loss: 1.3391 - val_acc: 0.5262\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.1509 - acc: 0.5955 - val_loss: 1.3639 - val_acc: 0.5177\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.1399 - acc: 0.5989 - val_loss: 1.3545 - val_acc: 0.5200\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.1268 - acc: 0.6033 - val_loss: 1.3397 - val_acc: 0.5326\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.1107 - acc: 0.6112 - val_loss: 1.3500 - val_acc: 0.5229\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.0998 - acc: 0.6142 - val_loss: 1.3607 - val_acc: 0.5193\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.0839 - acc: 0.6194 - val_loss: 1.3526 - val_acc: 0.5274\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.0716 - acc: 0.6226 - val_loss: 1.4028 - val_acc: 0.5128\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.0611 - acc: 0.6255 - val_loss: 1.3991 - val_acc: 0.5158\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.0452 - acc: 0.6331 - val_loss: 1.3926 - val_acc: 0.5187\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0319 - acc: 0.6375 - val_loss: 1.3750 - val_acc: 0.5250\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.0237 - acc: 0.6398 - val_loss: 1.3247 - val_acc: 0.5418\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.0094 - acc: 0.6463 - val_loss: 1.3313 - val_acc: 0.5403\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.9923 - acc: 0.6519 - val_loss: 1.3544 - val_acc: 0.5337\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 0.9816 - acc: 0.6534 - val_loss: 1.4238 - val_acc: 0.5181\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.9700 - acc: 0.6591 - val_loss: 1.3911 - val_acc: 0.5221\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.9546 - acc: 0.6630 - val_loss: 1.3646 - val_acc: 0.5370\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.9465 - acc: 0.6663 - val_loss: 1.3831 - val_acc: 0.5307\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 0.9335 - acc: 0.6702 - val_loss: 1.3518 - val_acc: 0.5378\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 0.9190 - acc: 0.6780 - val_loss: 1.4341 - val_acc: 0.5217\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 0.9075 - acc: 0.6810 - val_loss: 1.3723 - val_acc: 0.5394\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.8959 - acc: 0.6846 - val_loss: 1.3773 - val_acc: 0.5372\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.8880 - acc: 0.6873 - val_loss: 1.3611 - val_acc: 0.5396\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 0.8705 - acc: 0.6942 - val_loss: 1.4645 - val_acc: 0.5172\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 123us/step - loss: 0.8653 - acc: 0.6968 - val_loss: 1.5205 - val_acc: 0.5149\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,754,250\n",
      "Trainable params: 1,746,570\n",
      "Non-trainable params: 7,680\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 1.8236 - acc: 0.3617 - val_loss: 1.6091 - val_acc: 0.4322\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.5007 - acc: 0.4720 - val_loss: 1.5093 - val_acc: 0.4662\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 1.3802 - acc: 0.5163 - val_loss: 1.4549 - val_acc: 0.4869\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.2906 - acc: 0.5486 - val_loss: 1.4227 - val_acc: 0.4914\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.2182 - acc: 0.5736 - val_loss: 1.4013 - val_acc: 0.5013\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 1.1519 - acc: 0.5997 - val_loss: 1.3869 - val_acc: 0.5076\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 1.0915 - acc: 0.6208 - val_loss: 1.3765 - val_acc: 0.5104\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 1.0321 - acc: 0.6448 - val_loss: 1.3779 - val_acc: 0.5161\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.9756 - acc: 0.6668 - val_loss: 1.3838 - val_acc: 0.5149\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.9225 - acc: 0.6871 - val_loss: 1.3842 - val_acc: 0.5192\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.8694 - acc: 0.7054 - val_loss: 1.3978 - val_acc: 0.5188\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 0.8192 - acc: 0.7260 - val_loss: 1.4051 - val_acc: 0.5194\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.7674 - acc: 0.7453 - val_loss: 1.4253 - val_acc: 0.5204\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.7164 - acc: 0.7648 - val_loss: 1.4383 - val_acc: 0.5253\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.6693 - acc: 0.7831 - val_loss: 1.4487 - val_acc: 0.5211\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 0.6196 - acc: 0.8020 - val_loss: 1.4815 - val_acc: 0.5233\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.5797 - acc: 0.8156 - val_loss: 1.5102 - val_acc: 0.5235\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.5349 - acc: 0.8343 - val_loss: 1.5405 - val_acc: 0.5206\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.4937 - acc: 0.8490 - val_loss: 1.5870 - val_acc: 0.5156\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.4546 - acc: 0.8631 - val_loss: 1.5977 - val_acc: 0.5204\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.4183 - acc: 0.8760 - val_loss: 1.6347 - val_acc: 0.5170\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.3770 - acc: 0.8903 - val_loss: 1.6738 - val_acc: 0.5164\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.3475 - acc: 0.9018 - val_loss: 1.7212 - val_acc: 0.5131\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.3188 - acc: 0.9112 - val_loss: 1.7648 - val_acc: 0.5140\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2920 - acc: 0.9205 - val_loss: 1.7791 - val_acc: 0.5185\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.2627 - acc: 0.9310 - val_loss: 1.8249 - val_acc: 0.5152\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.2379 - acc: 0.9398 - val_loss: 1.8784 - val_acc: 0.5062\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.2181 - acc: 0.9445 - val_loss: 1.8882 - val_acc: 0.5104\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1980 - acc: 0.9522 - val_loss: 1.9499 - val_acc: 0.5130\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1822 - acc: 0.9572 - val_loss: 2.0001 - val_acc: 0.5100\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 0.1639 - acc: 0.9622 - val_loss: 2.0055 - val_acc: 0.5118\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.1509 - acc: 0.9660 - val_loss: 2.0708 - val_acc: 0.5098\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.1397 - acc: 0.9693 - val_loss: 2.0825 - val_acc: 0.5158\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1241 - acc: 0.9750 - val_loss: 2.1665 - val_acc: 0.5084\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1129 - acc: 0.9778 - val_loss: 2.1257 - val_acc: 0.5181\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1021 - acc: 0.9804 - val_loss: 2.1799 - val_acc: 0.5092\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0942 - acc: 0.9823 - val_loss: 2.2179 - val_acc: 0.5131\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.0930 - acc: 0.9817 - val_loss: 2.2232 - val_acc: 0.5116\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0848 - acc: 0.9840 - val_loss: 2.2677 - val_acc: 0.5146\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0743 - acc: 0.9873 - val_loss: 2.2854 - val_acc: 0.5115\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0704 - acc: 0.9884 - val_loss: 2.3445 - val_acc: 0.5075\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0639 - acc: 0.9901 - val_loss: 2.3356 - val_acc: 0.5189\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0598 - acc: 0.9906 - val_loss: 2.3798 - val_acc: 0.5152\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0565 - acc: 0.9911 - val_loss: 2.3900 - val_acc: 0.5109\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0493 - acc: 0.9933 - val_loss: 2.4163 - val_acc: 0.5153\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0468 - acc: 0.9935 - val_loss: 2.4419 - val_acc: 0.5130\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.0439 - acc: 0.9934 - val_loss: 2.4617 - val_acc: 0.5142\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.0463 - acc: 0.9924 - val_loss: 2.4841 - val_acc: 0.5165\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0465 - acc: 0.9924 - val_loss: 2.5283 - val_acc: 0.5129\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0423 - acc: 0.9935 - val_loss: 2.5330 - val_acc: 0.5068\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"Code Here\n",
    "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
    "\"\"\"\n",
    "\n",
    "# dropout\n",
    "model = build_mlp_dropout(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "exp_name_tag = \"dropout-%d\" % (256)\n",
    "results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                'valid-loss': valid_loss,\n",
    "                                'train-acc': train_acc,\n",
    "                                'valid-acc': valid_acc}\n",
    "\n",
    "\n",
    "#l1 regulization\n",
    "model = build_mlp_l1(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "\n",
    "    # Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "exp_name_tag = \"l1_regulization-%d\" % (BATCH_SIZE)\n",
    "results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                     'valid-loss': valid_loss,\n",
    "                                     'train-acc': train_acc,\n",
    "                                     'valid-acc': valid_acc}\n",
    "\n",
    "#Batch normalization\n",
    "model = build_mlp_before(input_shape=x_train.shape[1:])\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)\n",
    "\n",
    "# Collect results\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "exp_name_tag = \"before-Batch-normalization%d\" % (BATCH_SIZE)\n",
    "results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                'valid-loss': valid_loss,\n",
    "                                'train-acc': train_acc,\n",
    "                                'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Code Here\n",
    "將結果繪出\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond)\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond)\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond)\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
